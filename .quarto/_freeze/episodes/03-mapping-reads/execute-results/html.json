{
  "hash": "3d76dd98b6fbccfe53527aaf5c07ef6e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"From reads to alignments\"\nengine: knitr\nformat:\n    html:\n        fig-width: 5\n        fig-height: 4\n        code-annotations: hover\n---\n\n\n\n\n\n::: {.mwadd}\n\n## Feedback:\n\nI think the challenge here is to both provide insights into the mapping (etc) process as well \nas supply the participants with practical means to perform mapping themselves.\n\n#### How make sure ppl can apply themselves?\n\nPractical means can also be the Galaxy server, or another existing pipeline, and this episode just functions as a way \nto make people understand what's going on.\n\nI think what makes it challenging is that currently the process is explained by a single \nexample, and people won't know how to modify the process for different organisms, types of data etc.\nThe code shown however already almost constitutes a pipeline template. Perhaps we can: \n\n- Also add some \"extended info\" where we provide a more extensive command template that includes options for different situatinos (e.g. single read, different read length, different organism, etc).\n- Include a full template script at the end, that includes documentation (in comments) about how one should run and adjust the commands for their needs. \n    - (might already exist somewhere)\n\nHowever, it will also remain a challenge that people need to set up a chrunchomics account and get things \nworking there. Perhaps we can write a brief tutorial how to set this up as well? (This can than be material not \nincluded in the course, but available to those interested.)\n\n#### Adding structure\n\nI think it would also be beneficial to \"paint the big picture\" upfront (experiment --> count table, see below)\nand also briefly place each of the steps of this episode in the \"big picture\" pipeline at the beginning of each paragraph.\n\n#### What about terminal skills?\n\nChallenge: people need to understand terminal, piping, shell scripts, etc. Seems a bit much. Maybe take a moment for basics of those too? (And do these things with live coding?) Which editor to use?\n\n- Quick tour of terminal basics would include imho:\n    - Navigation (cd, ls, cat, mkdir, pwd, mv, cp, piping?, echo? setting parameters?)\n    - Calling a program (e.g. \"python\", or \"echo hello\")\n    - Writing a script that can be called by a program (for loop that calls hello world python script?)\n    - See also: https://swcarpentry.github.io/shell-novice/\n\n#### How to teach this episode?\n\nI think here it would also be beneficial to do a type along in Caprentries style?\n\nThe code is not extremely long, and will be instructive.\n\nThere would need to be some more explaining in between.\n\nOther option: make it purely a notebook that people go through in their own pace and \nexplain stuff personally or colloqually if appropriate (this is how the ML workshop I followed\ndid it).\n\n#### Perhaps additional useful contents\n\n- Movie about sequencing protocol:\n    - [YT illumina](https://www.youtube.com/watch?v=HMyCqWhwB8E)\n\n:::\n\n\n::: {.mwadd}\n\nPerhaps an image like this would be instructive to give a big picture (I made this in powerpoint):\n\n![RNA-seq overview](../images/RNA-seq-overview.png){fig-alt=\"RNA-seq data\" fig-cap=\"Overview of RNA-seq pipeline.\" width=70% style=\"background:#fff;\"}\n\n:::\n\n\nThe moment is there: you received the FASTQ files from your sequencing provider! Now what?\n\n## Quality control: `fastqc`\n\n::: {.mwadd}\n\nI think some context is lacking here. What is our goal? \nMaybe add paragraph at start that outlines the whole process?\n\nOur goal is to obtain count table, but what we have is just sequence information.\n\nSo we should convert sequence information to genes, and count observations of each genes.\n\nBeforehand, we want to make sure sequence information is solid --> QC.\n\n:::\n\nThe first step in the RNA-seq workflow is to assess the quality of the sequencing reads. Sequence reads generated from next-generation sequencing technologies come in the FASTQ file format. This file format evolved from FASTA: it contains sequence data, but also contains quality information. For a single record (sequence read) there are four lines, each of which are described below:\n\n|Line|Description|\n|----|-----------|\n|1|Always begins with '@' and then information about the read|\n|2|The actual DNA sequence|\n|3|Always begins with a '+' and sometimes the same info in line 1|\n|4|Has a string of characters which represent the quality scores; must have same number of characters as line 2|\n\nLet's run `fastqc` on one sample:\n\n::: {.mwadd}\n\n- fastqc is now suddenly used without introduction. \n- also terminal commands are used without introduction\n\nHowever, I like the focus on practical stuff, without extensive explantations.\n\nPerhaps work with information boxes to explain what each tool is?\n\n:::\n\n\n\n::: {.callout-tip} \n## Bio-inf tool: FastQC\n\nFastQC is a quality control tool for DNA or RNA sequencing data. It takes the raw sequence files (FASTQ format) and quickly checks for common issues, like overall read quality, presence of adapters, unusual base composition, or overrepresented sequences. The output is a simple report with plots and summaries that help you see if your sequencing run worked well or if there might be problems before doing further analysis.\n\n<mwadd>(added by mw/text by chatGPT)</mwadd>\n:::\n\n\n\n\n::: {.cell filename='bash'}\n\n```{.bash .cell-code}\nfastqc -o fastqc /datasets/Arabidopsis_sample1.fq.gz\n```\n:::\n\n\n\n\nDoing this manually for every sample would be quite tiring, especially when we would have many samples. Let's write a `bash` for loop to take care of this for us:\n\n\n\n\n::: {.cell filename='bash'}\n\n```{.bash .cell-code}\nfor filename in  /datasets/*.fq.gz # <1>\n  do\n    fastqc -o fastqc $filename # <2>\n  done\n```\n:::\n\n\n\n\n<mwadd>I think for a command like this, a template file (see comments above) with more extensive documentatino makes sense. Comments could be added explaining very precisely what every part of the command is doing (including every small detail, e.g. do and done being keywords that begin/end the loop etc.).</mwadd>\n\n1. Here we define a variable `filename` that will subsequently get the values of all datasets matching the `/datasets/*.fq.gz` statement, where `*` acts as a wildcard.\n2. Here we add the actual command, where `$filename` will subsequently be filled in with all of our four filenames.\n\n`fastq` generates reports of each sample in `.html` format:\n\n\n\n\n::: {.cell filename='bash'}\n\n```{.bash .cell-code}\nls ... # TODO: add ls outcome here to show that we have 4 .html files now\n```\n:::\n\n\n\n\nLet's download one of them, and inspect the results:\n\n\n\n\n::: {.cell filename='bash'}\n\n```{.bash .cell-code}\n# TODO: download to local instructions here (if you are working on a server)\n```\n:::\n\n\n\n\n`fastqc` gives the reads of each sample a score (Pass, Warning, or Fail) on several different modules and this is reported in the **Summary**. The next section contains basic statistics like the number of reads, average sequence length, and the GC content. Generally it is a good idea to keep track of the total number of reads sequenced for each sample and to make sure the read length and %GC content is as expected. One of the most important analysis modules is the **“Per base sequence quality”** plot. This plot provides the distribution of quality scores at each position in the read across all reads. This plot can alert us to whether there were any problems occuring during sequencing and whether we might need to contact the sequencing facility.  Other modules are discussed in detail [here](https://hbctraining.github.io/Intro-to-rnaseq-hpc-salmon/lessons/qc_fastqc_assessment.html). Note that nearly all sequencing datasets will show yellow warnings or red fails: `fastqc` is quite conservative. Your experiment is not lost if you get warnings or fails, but it warrants additional inspection of the reads.\n\n<mwadd>Perhaps also suggest that if they suspect something wrong they could contact us/their sequencer/their favorite bioinformatician.</mwadd>\n\n**TODO: add screenshots of good/bad fastqc results**\n\n::: {.mwadd}\n\nI think it would be nice to not only include screenshot good/bad fastqc results, \nbut also clearly (e.g. add some arrows with text) annotate those pictures explaining/highlighting\nhow to interpret important numbers / features.\n\nSort of a \"cheat sheet\" for fastq.\n\n:::\n\n## Trimming: `trimmomatic`\n\nA common anomaly detected by `fastqc` is sequencing adapters still being present some of the the reads (shown in **Overrepresented sequences** table). This is known as 'adapter contamination', and the presence of these adapter sequences in the reads might affect how the reads map to the genome of interest. So, we need to get rid of them. We will `trimmomatic` to do this. In addition, we can ask `trimmomatic` to trim low quality bases from the reads.\n\n\n\n\n::: {.cell filename='bash'}\n\n```{.bash .cell-code}\n# TODO: add trimmomatic command here\n```\n:::\n\n\n\n\n::: {.callout-tip title=\"Exercise\" icon=\"false\"}\nAfter running `trimmomatic`, the adapter contamination should be gone.\n\n1. How could you check whether `trimmomatic` indeed did it's job?\n2. Write a command to check this.\n:::\n\n::: {.callout-caution title=\"Solution\" collapse=\"true\" icon=\"false\"}\n1. We can run `fastqc` again, this time on the trimmed reads.\n2. \n\n\n\n::: {.cell filename='bash'}\n\n```{.bash .cell-code}\nfastqc -o /workspace/fastqc /datasets/Arabidopsis_sample1.trimmed.fq.gz\n```\n:::\n\n\n\nBy inspecting the `.html` report of the trimmed reads, we should see that the quality of the read sets has now improved.\n:::\n\n## Mapping: `STAR`\n\nOur reads are now ready for mapping. Mapping reads means figuring out where each read from the RNA-seq experiment originally came from within the genome. For RNA-seq experiments, it's important to pick a **splice-aware** aligner, since a RNA-seq read can span an exon-intron-exon boundary \n\n**TODO: add a figure here to demonstrate this, like the one found [here](https://hbctraining.github.io/Intro-to-rnaseq-hpc-O2/lessons/03_alignment.html)**.\n\n::: {.callout-tip title=\"Question\" icon=\"false\"}\nSo, for RNA-seq we need splice-aware aligners. Can you come up with an experiment that would not require a splice-aware aligner program?\n:::\n\n::: {.callout-caution title=\"Solution\" collapse=\"true\" icon=\"false\"}\nIn experiments where we don't need to think about exon-intron boundaries. This is the case when the reads originate from genomic DNA, for example for whole genome sequencing experiments, or enrichment sequencing experiments like Chip-Seq. \n:::\n\nTo use an aligner, we must first get the **reference genome** and then *index* the reference genome. Indexing the genome prepares the genome in a way that allows a computer to search it efficiently. The genome, a multi-million basepair long string of text, is encoded into a different, computer-friendly datastructure such as a suffix tree. The details of this procedure are beyond the scope of this workshop, but it's important to do it. So, let's go ahead and download the *Arabidopsis thaliana* reference genome, and index it:\n\n::: {.mwadd}\nI think important information is where you can get reference genomes and additional information (eg gtf files). \nWill be usefull to add info-box about this as well. E.g. include:\n\n- typically can be downloaded from NCBI/Ensembl\n- beware there are multiple versions, track which one used\n- you need to click here and here to find and download genome\n\n:::\n\n\n\n\n::: {.cell filename='bash'}\n\n```{.bash .cell-code}\n# TODO: Add download command here (via wget), OR already have the genome in the github repo\n# TODO: Add STAR index command here\n```\n:::\n\n\n\n\nAllright, let's finally run `STAR`: \n\n\n\n\n::: {.cell filename='bash'}\n\n```{.bash .cell-code}\n# TODO: Add STAR command here\n```\n:::\n\n\n\n\nWe can inspect a mapping summary in a file generated by STAR called `final.out`:\n\n\n\n\n::: {.cell filename='bash'}\n\n```{.bash .cell-code}\n# TODO: Add cat final.out output\n```\n:::\n\n\n\n\nIt's important to check how many reads did not map to the reference genome. A high proportion of unmapped reads can be a warning sign that something went wrong in your experiment or analysis. The explanations may be technical (bad read quality), bioinformatical (perhaps you used the wrong reference genome!), or biological --- it has been well documented that around 11% of primate and rodent cell-line RNA-seq datasets available on NCBI in 2015 were contaminated with mycoplasma RNA ([Olarerin-George & Hogenesch, 2015](https://pmc.ncbi.nlm.nih.gov/articles/PMC4357728/)). Likewise, 8,5% of all *Arabidopsis thaliana* NCBI RNA-seq datasets are contaminated with a virus that does not cause any disease symptoms, but can cover up to 80% of all reads generated in an RNA-seq experiment ([Verhoeven et al., 2022](https://nph.onlinelibrary.wiley.com/doi/full/10.1111/nph.18466)). That said, we don't need to aim for 100% reads mapped to the reference genome. There will always be some contamination, or your studied individual possesses genetic information not present in the reference genome. \n\n**TODO: (Maybe as an additional exercise?) Add one subsetted dataset to demonstrate this, from the verhoeven paper.**\n\n<mwadd>Can we add some quantitative guidelines when people need to worry? (To get these numbers, we could also inquire at ppl who regularly perform mapping, like MAD group ppl (Wim/Martijs?).)</mwadd>\n\n### BAM and SAM files\n\n::: {.mwadd}\nNot sure, consideration: is \"the mapped reads\" use of jargon, that might require some explaining? Same would then apply to other jargon.\n\nE.g. sugg: \"The output of STAR are files in which the mapping of our original sequences to DNA locations are stored. These are .bam and .sam files (..)\"\n:::\n\nThe mapped reads are stored in a `.bam` file by `STAR`. `.bam` and `.sam` files keep information for each individual read and its alignment to the genome. `.sam` files do this in a tab-seperated, human readable format, while `.bam` files store the same information in a binary file format that's not readable for humans, but is much more efficient to process and store by computers. `samtools` is a widely used program to inspect and manipulate `.sam` and `.bam` files. Like many command line programs, `samtools` commands can be connected to each other via the pipe symbol `|`, and the results can be stored in a new file using the `>` symbol. \n\n\n\n\n::: {.cell filename='bash'}\n\n```{.bash .cell-code}\nhead xyz.sam # TODO: add correct filename here\n```\n:::\n\n\n\n\n::: {.callout-tip title=\"Exercise\" icon=\"false\"}\nUse the `head` command to inspect a `.bam` file. \n\n1. What do you see?\n2. Use `samtools view` command, piped (using `|`) into a common Unix program, to inspect the first 10 lines of the file. \n:::\n\n::: {.callout-caution title=\"Solution\" collapse=\"true\" icon=\"false\"}\n\n\n\n::: {.cell filename='bash'}\n\n```{.bash .cell-code}\nhead xyz.bam # TODO: add correct filename here\n```\n:::\n\n\n\n\nThe output looks like gibberish, because `.bam` files are a binary file format. You can use `samtools view` to make samtools read the binary file, and then pipe that result into the `head` function to show the first 10 lines:\n\n\n\n\n::: {.cell filename='bash'}\n\n```{.bash .cell-code}\nsamtools view xyz.bam | head # TODO: add correct filename here\n```\n:::\n\n\n\n:::\n\n::: {.callout-tip title=\"Exercise\" icon=\"false\"}\nUse the two following commands on a `.bam` file, and interpret the output.\n\n1. `samtools flagstat`\n2. `samtools idxstats` (Note: before running this command, you need to index the `.bam` file using `samtools index xyz.bam`) \n:::\n\n::: {.callout-caution title=\"Solution\" collapse=\"true\" icon=\"false\"}\n\n1. `samtools flagstat` shows us (just like the `STAR` log file) how many reads were mapped correctly. In addition, it tells us whether read pairs (if mapping paired-end data) mapped together as expected.\n2. `samtools idxstats` shows us how many reads were mapped to each chromosome of the reference genome. This is useful to confirm whether the entire genome is evenly covered, or that there may be overrepresentation on e.g. the mitochondrial DNA.\n:::\n\n::: {.callout-tip title=\"Exercise\" icon=\"false\"}\nSo far, we only trimmed and mapped one sample. Write a `bash` for loop to process all four samples.\n:::\n\n::: {.callout-caution title=\"Solution\" collapse=\"true\" icon=\"false\"}\n\n\n\n::: {.cell filename='bash'}\n\n```{.bash .cell-code}\nfor filename in  /datasets/*.fq.gz \n  do\n    # TODO: add trimmomatic command\n    # TODO: add STAR command\n  done\n```\n:::\n\n\n\n:::\n\n### Inspecting the mapping on a genome browser\n\n<mwadd>I like this a load, but in view of time I think this part should be made optional. Maybe existence of viewer can be mentioned during \"lecture\" part of workshop, but only talk about screenshot for ±1 minute.</mwadd>\n\n**TODO**:\n\n- download one bam + bai file and inspect mapping in genome browser\n- observe: only (or at least majority) reads map in genes (if this is not the case, something is wrong! either gDNA contamination, or bad annotation) \n- observe split reads across introns\n- we can't inspect all samples manually like this, so we will need to count reads, which we will do in the next section.\n\n\n## Counting: `featureCounts`\n\n\n\n\n::: {.cell filename='bash'}\n\n```{.bash .cell-code}\n# TODO: add featureCounts command here\n```\n:::\n\n\n\n\n## A note on the specific tools used here\n\nIn bioinformatics, there are often many ways to reach the same goal. Here we have selected mapping, trimming and counting tools that we have available and have experience with, but there are many others that perform just as well. The following table highlights a few popular alternative options:\n\n| Task | Tool used here | Alternative tools |\n| ---- | -------------- | ----------------- |\n| Trimming | `Trimmomatic` | `cutadapt`, `fastp` |\n| Mapping | `STAR` | `HISAT2` |\n| Counting | `featureCounts` | `StringTie` |\n\n<mwadd>Potentially add: trimgalore, bwa-mem(2) (not splice aware)</mwadd>\n\n## Streamlining read mapping procedure\n\nIf you find this process quite cumbersome, then I have good news for you! There are *pipelines* available that streamline the chain of commands required for mapping:\n\n- [snakemake_rnaseq](https://github.com/BleekerLab/snakemake_rnaseq), developed at the Bleeker Lab (UvA).\n- [nf-core/rnaseq](https://nf-co.re/rnaseq/3.19.0), developed and maintained by the Nextflow community.\n\n<mwadd>To add: Galaxy server</mwadd>\n\nA full instruction of these pipelines is beyond the scope of this workshop. Also, we wish to highlight that it is *very insightful* to have run all the steps by yourself rather than in a pipeline.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}