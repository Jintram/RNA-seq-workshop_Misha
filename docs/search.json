[
  {
    "objectID": "notes_mw.html",
    "href": "notes_mw.html",
    "title": "Notes with RNA-seq course Misha",
    "section": "",
    "text": "by Martijn Wehrens (2025-08)\n\n\nMisha’s outline of the workshop:\n\nSetting up software (beforehand)\n\nFor Part 1: use Google Colab\nFor Part 2: install some R packages\n\nDesigning an RNA-seq experiment\n\nCentral tendency, spread, two-sample test\nConceptual idea of power (lacks definition and estimation of power)\nBrief discussion power (incl ~definition), and Liu2014/Schurch2016 focusing on replicate vs. depth .\nExperimental design (avoid confounding)\nConcluding remarks\n\nCreating the count table (terminal-based)\n\nUnderstanding which files are involved\nQuality control of FASTQ files\nMapping & creating a count table\n\n“QC” using PCA and sample clustering\n\n\n\n\n(See also obsidian notes) How to teach this??"
  },
  {
    "objectID": "notes_mw.html#overview",
    "href": "notes_mw.html#overview",
    "title": "Notes with RNA-seq course Misha",
    "section": "",
    "text": "Misha’s outline of the workshop:\n\nSetting up software (beforehand)\n\nFor Part 1: use Google Colab\nFor Part 2: install some R packages\n\nDesigning an RNA-seq experiment\n\nCentral tendency, spread, two-sample test\nConceptual idea of power (lacks definition and estimation of power)\nBrief discussion power (incl ~definition), and Liu2014/Schurch2016 focusing on replicate vs. depth .\nExperimental design (avoid confounding)\nConcluding remarks\n\nCreating the count table (terminal-based)\n\nUnderstanding which files are involved\nQuality control of FASTQ files\nMapping & creating a count table\n\n“QC” using PCA and sample clustering"
  },
  {
    "objectID": "notes_mw.html#remarks-by-me",
    "href": "notes_mw.html#remarks-by-me",
    "title": "Notes with RNA-seq course Misha",
    "section": "",
    "text": "(See also obsidian notes) How to teach this??"
  },
  {
    "objectID": "episodes/06-practice-more.html",
    "href": "episodes/06-practice-more.html",
    "title": "Practice on your own",
    "section": "",
    "text": "In this workshop, we went all the way from experimental design, to bioinformatic processing of .fastq files, to differential gene expression analysis in DESeq2. We hope that you are now ready to design and analyze your own transcriptome experiments. Remember that we only covered the very basics of transcriptome analysis, expect to learn a lot more when you start analyzing your own data.\nIf you first want to practice more, or don’t have your own data yet, consider analyzing publicly available RNA-seq datasets. Papers often make their raw sequencing reads available on NCBI or ENA, which you can download to reanalyze. For now, we collected three count tables to practice DESeq2 analysis, from three different domains of the life sciences.\n\nThe neuroscientist\nTODO Find a neuroscience count table with associated metadata. Something brain development related? Maybe from the Frank Jacobs lab?\n\n\nThe microbiologist\nTODO Find a microbiology count table with associated metadata. Bacteria response to antibiotics? Bacteria during infection?\n\n\nThe plant scientist\nTODO Find a plant science count table with associated metadata. Tomato dataset from Petra Bleeker? Rice dataset from Harro Bouwmeester?",
    "crumbs": [
      "Practice on your own"
    ]
  },
  {
    "objectID": "episodes/01-setup.html",
    "href": "episodes/01-setup.html",
    "title": "Setting up",
    "section": "",
    "text": "Any bioinformatics project requires setting up the required software. Let’s go through the setup for this RNA-seq workshop here.",
    "crumbs": [
      "Setting up"
    ]
  },
  {
    "objectID": "episodes/01-setup.html#from-reads-to-alignments",
    "href": "episodes/01-setup.html#from-reads-to-alignments",
    "title": "Setting up",
    "section": "From reads to alignments",
    "text": "From reads to alignments\nThis part is the ‘hardcore’ bioinformatics part of this workshop. These steps are nearly always performed using command-line programs, which can be accessed via the Terminal (macOS, Linux) or WSL (Windows). For this workshop, we prepared a Google Colab environment where we will run the commands. Access to the Google Colab environment requires a Google account.\n\nFind the google colab here (TODO: this is a placeholder from a workshop I followed, I plan to make a similar one for our workshop)\n\nIn reality, you will often have so many samples and reads that you will need access to a compute cluster with more compute power (CPUs), working memory (RAM), and storage space. At the University of Amsterdam, we use Crunchomics. Crunchomics comes with many popular bioinformatics pre-installed, additional programs can be installed using conda.",
    "crumbs": [
      "Setting up"
    ]
  },
  {
    "objectID": "episodes/01-setup.html#differential-gene-expression-with-deseq2",
    "href": "episodes/01-setup.html#differential-gene-expression-with-deseq2",
    "title": "Setting up",
    "section": "Differential gene expression with DESeq2",
    "text": "Differential gene expression with DESeq2\nFor this part of the workshop, we will use R. Please make sure you have R and RStudio installed on your computer. In addition, you will need to install the following packages, via two different routes:\nInstall the following packages via install.packages()\n\n\n\nR\n\ninstall.packages('tidyverse')\ninstall.packages('patchwork')\ninstall.packages(\"pheatmap\")\ninstall.packages(\"BiocManager\")\n\n\nInstall the following packages via Bioconductor\n\n\n\nR\n\nBiocManager::install(\"apeglm\")\nBiocManager::install(\"clusterProfiler\")\nBiocManager::install(\"org.At.tair.db\")\nBiocManager::install(\"DESeq2\")\n\n\nTest whether DESeq2 was installed properly by loading it:\n\n\n\nR\n\nlibrary(DESeq2)\n\n\nDuring the workshop, we will not have time to install the packages, or to troubleshoot installation problems. Please try to install the packages before the workshop. You can always contact the workshop organizers if you run into problems.",
    "crumbs": [
      "Setting up"
    ]
  },
  {
    "objectID": "episodes/01-setup.html#getting-the-data",
    "href": "episodes/01-setup.html#getting-the-data",
    "title": "Setting up",
    "section": "Getting the data",
    "text": "Getting the data\nTODO: for the bioinformatics part, we will use the following Zenodo archive",
    "crumbs": [
      "Setting up"
    ]
  },
  {
    "objectID": "episodes/02-experimental-considerations.html",
    "href": "episodes/02-experimental-considerations.html",
    "title": "Before the experiment",
    "section": "",
    "text": "(MW)\n\n\nI thikn the general outline is there, though I would consider some changes.\nThe tutorial is now quite text heavy, I think it could benefit from adding more diagrams, highlight boxes, lists etc that emphasize take home messages and learning goals, and which clearify the logical structure of the material.\nI would make some edits in topics and structure, see suggested structure below and other comments.\nI also wonder how to best convey this material to participants. Perhaps an idea is to create some small dataset (I already have some code to create simulated data based on a toy model, see [1] and [2], could be used but not necessarily), and do a code-along session in Carpentries style using that example? If smartly designed, this could highlight the main issues in a dataset.\nI think additionally it’s a good idea to add some literature suggestions re. these topics. Some suggestions (some were already included):\n\nJeon2023, which discusses stat power for RNA-seq.\n\nCites Schurch2016\nCites Wu2015\n\nLi2022, which evaluates several RNA-seq DEG analysis packages.\n\n(Perhaps this comparison is convenient for later episode)\n(I also made an overview how many times each package was cited last year)\n\n\n\n\n\n\nRefresh basic stats to be able to discuss topics below (basic comparison w/ t-test)\nExplain challenges related to RNA-seq experiments\n\nMultiple testing\nHaving enough stat power to counter noise\nPitfalls when designing experiments, e.g. \n\nToo little samples\nExpecting to find “something” (hypothesis-driven vs. exploratory)\nFalse positives and difficult to intrepret results (related previous point)\n\n\nConcrete tools and quantitative advice to aid in experimental design\n\n(Which adress above challenges.)\nBefore diving into the bioinformatics of RNA-seq experiments, it’s good to take a step back and think about experimental design and refresh your statistical knowledge. After all, an RNA-seq experiment is also an experiment like any other.",
    "crumbs": [
      "Before the experiment"
    ]
  },
  {
    "objectID": "episodes/02-experimental-considerations.html#hypothesis-testing",
    "href": "episodes/02-experimental-considerations.html#hypothesis-testing",
    "title": "Before the experiment",
    "section": "Hypothesis testing",
    "text": "Hypothesis testing\n\n\nThis part explains basic statistics, which most people hopefully know already, quite elaborately. Is it the idea people go over this fast?\nPerhaps consider this knowledge that needs refreshing and point out some important nuances\n\nTechnical: (like central tendency &lt;-&gt; mean, effect size)\nRaise important practical caveats, like multiple testing (make ppl understand this problem, and mention we address this later in DE analysis)\n\n\n\nIn an RNA-seq experiment, you will analyze the expression levels of thousands of genes. Before doing that, let us consider statistical tests and their associated p-values for a single gene. Let’s say you are studying a plant gene called “heat stress trancripion factor A-2 (HSFA2)”, whose expression might be induced by…. heat stress (you might have guessed that). You could phrase your null hypothesis:\n\n“The average HSFA2 gene expression is the same in normal conditions and under heat stress in my Arabidopsis seedlings”\n\nThe corresponding alternative hypothesis could then be:\n\n“The average HSFA2 gene expression is different under heat stress compared to normal conditions in my Arabidopsis seedlings”\n\nYou set up an experiment in the greenhouse. You grow Arabidopsis thaliana seedlings, and give half of them a heat stress treatment. Then, you take samples of 20 plants in both control and heat stressed conditions, and measure the expression levels of HSF2A. Let’s visualize this in a boxplot made in R, using the ggplot2 package.\n\n\n\nR\n\nlibrary(tidyverse)\nset.seed(1992)\n\ncontrol &lt;- tibble(expression = rnorm(n = 20, mean = 2, sd = 0.6), \n                    condition = \"control\")\nheat_stress &lt;- tibble(expression = rnorm(n = 20, mean = 3.4, sd = 0.3),\n                    condition = \"heat stress\") \n                         \nexperiment &lt;- bind_rows(control, heat_stress)\n\nggplot(experiment, aes(x = condition, y = expression)) + \n    geom_boxplot(aes(fill = condition), alpha = 0.5, outlier.shape = NA) +\n    geom_jitter(width = 0.2, alpha = 0.5) +\n    theme_classic()\n\n\n\n\n\n\n\n\n\nIndeed, HSF2A is highly expressed in heat stressed plants. The thick line of the boxplots show the median HSF2A expression in both groups. The median is a measure of central tendency. You will also see that the individual datapoints are dispersed around the boxplot: quantifying this gives us a measure of the spread of the data. An example of such a measure of spread is the standard deviation. It looks like our heat stressed plants display a more narrow spread of the data, compared to the plants grown in the control condition.\n\n\n\n\n\n\nQuestion\n\n\n\nCan you name another measure of central tendency? And another one for the measure of spread?\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAnother often used measure of central tendency would be the mean. As for the measure of spread, the variance (square of the standard deviation) or the standard error (standard deviation divided by the square root of the number of observations) are often used.\n\n\n\nLet’s test whether the means of the two groups are equal or not. We do this with a two-sample t-test.\n\n\n\nR\n\nt.test(x = control$expression,\n       y = heat_stress$expression,\n       alternative = \"two.sided\" ,      \n       var.equal = FALSE,             # important as the variance do not seem equal\n       conf.level = 0.95)             # this corresponds to alpha = 0.05 \n\n\n\n    Welch Two Sample t-test\n\ndata:  control$expression and heat_stress$expression\nt = -12.237, df = 25.636, p-value = 3.312e-12\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.600116 -1.139603\nsample estimates:\nmean of x mean of y \n 1.970023  3.339883 \n\n\nBecause the p-value &lt; 0.05, we can safely reject our null hypothesis, and claim that we have discovered that Arabidopsis significantly upregulates the expression of HSF2A under heat stress. Sounds like it’s time to write this down and submit a manuscript to Nature!\nI don’t agree with putting it the way as above. One of the big challenges of RNA-seq is handling multiple testing properly. In RNA-seq, I would not consider a raw p=±0.05 value indicative of anything.\n\nStatistical power\n\nI think this section should offer some clear methods to estimate power, not only qualitative advice. I think we should include (somewhere in the material):\n\nR’s power testing function.\n\nExplain ‘power.t.test()’ to illustrate the idea.\nSee e.g. here\nBut this doesn’t address the multiple testing issue.\n\nPackages to estimate required sample size for RNA-seq specifically, that address the multiple testing issue.\n\nMaybe shouldn’t discuss in detail, but point people towards this, and raise awareness.\nSee e.g.:\n\nWu2015, with the PROPER package, that estimates required sample sizes to achieve stat power X.\nJeon2023\n\n(I didn’t deeply look into this, but this this is an important topic. Discuss further?)\n\n\n\n\n\nStatistical power is the ability of your experimental sample population to detect differences (in this case, gene expression differences) that actually exist in the real population of your study species out there in the world. There are two main error one could make when testing hypotheses. Type I errors occur when the null hypothesis is rejected wrongly — you detect a significant difference while in reality there is no difference in gene expression (“false positive”). Type II errors also are common in hypothesis testing — they arise if you accept the null hypothesis when in fact a treatment effect exists (“false negative”)\nThe power of an experiments is affected by several factors. We have seen so far:\nI think an explanatory image with two distributions would be highly useful here.\n\nThe number of replicates: more samples results in a higher power\nSize of the effect: bigger differences between groups are easier to detect\nVariability of the data: less noise is more power\nConfidence level threshold: usually, this is 0.05, but we can make our analysis more or less stringent by changing this to 0.01 or 0.1",
    "crumbs": [
      "Before the experiment"
    ]
  },
  {
    "objectID": "episodes/02-experimental-considerations.html#what-determines-the-power-of-an-rna-seq-experiment",
    "href": "episodes/02-experimental-considerations.html#what-determines-the-power-of-an-rna-seq-experiment",
    "title": "Before the experiment",
    "section": "What determines the power of an RNA-seq experiment?",
    "text": "What determines the power of an RNA-seq experiment?\nSee earlier comments, I think this section should offer some more concrete quantitative advice.\nRNA-seq experiments measure the expression levels of thousands of genes simultaneously, meaning we perform thousands of statistical tests at once. To avoid making too many false discoveries (type I errors), we have to correct for multiple testing. However, it also reduces statistical power — increasing the chance of missing real differences (type II errors). As a result, RNA-seq experiments can have lower power, especially for detecting small or subtle changes in gene expression.\nSo, how do we deal with that? We have a few parameters to play with when designing an RNA-seq experiment, including deciding the number of reads per sample, and the number of samples per treatment. Liu et al., 2014 investigated this systematically in an RNA-seq experiment with a human cell line. An exerpt from figure 1 is show below:\n\nImage credits: Liu et al., 2014\nThe figure shows the relationship between sequencing depth and number of replicates on the number of differentially expressed genes (DEGs) identified. It illustrates that biological replicates are of greater importance than sequencing depth. Above 10M-15M reads per sample, the number of DEGs increases marginally, while adding more biological replicates tends to return more DEGs. A similar conclusion was also reached by Schurch et al., 2016. So, if your experiment is limited by a certain sequencing budget, it is almost always better to add more replicates than to sequence more reads of a limited number of samples. However, there are some caveats here. Say you are interested in the transcriptome of a fungal pathogen growing in plant roots. In such samples, most reads will probably come from the plant roots, so you will need to sequence deeply (that is, many reads from the same sample) to find DEGs from the fungal pathogen.",
    "crumbs": [
      "Before the experiment"
    ]
  },
  {
    "objectID": "episodes/02-experimental-considerations.html#experimental-design",
    "href": "episodes/02-experimental-considerations.html#experimental-design",
    "title": "Before the experiment",
    "section": "Experimental design",
    "text": "Experimental design\nThis is quite a blob of text to say “avoid confounding”, and concrete advice is a bit hidden in the text; perhaps re-structure this using good/bad example experimental design? (I guess also text not finished yet, as it says “first of all”, but no second or third things are mentioned.)\nIn a typical biological experiment, you will encounter various sources of variation that are either:\n\nDesirable because they are part of your experimental factors. For example, the genotype, treatment, or timepoint.\nUndesirable because you are not interested in them. This could be: batch of RNA isolation, location of plants in the greenhouse, …\n\nUndesirable variation is unavaidable, but there are some practices to limit their impact. First of all, make sure that you don’t confound your experimental factors with undesirable sources of variation by properly randomizing your treatments. For example, if you have too many samples to isolate RNA in one day of labwork, make sure you don’t isolate RNA from samples with genotype A on day 1, and genotype B on day 2. In this case, you will never be able to know whether genes were differentially expressed because the genotypes of the samples differ (very interesting!) or because RNA was isolated on two different days (not very interesting). Instead, mix your samples of genotype A and B over your two RNA isolation days. Still, you should always record known sources of undesirable variation so you can correct for it later. There’s much more to be said about this, for more details see these materials from Harvard Chan Bioinformatics Core.",
    "crumbs": [
      "Before the experiment"
    ]
  },
  {
    "objectID": "episodes/02-experimental-considerations.html#concluding-remarks",
    "href": "episodes/02-experimental-considerations.html#concluding-remarks",
    "title": "Before the experiment",
    "section": "Concluding remarks",
    "text": "Concluding remarks\nI would replace this text with a list of take home messages.\nIn this section, we refreshed our statistics knowledge, and discussed how this applies to RNA-seq experiments. Hopefully, this enables you to craft a well-designed and controlled RNA-seq experiment. Now, head to the lab or greenhouse, perform your experiment, and extract high-quality RNA. How to do this will depend on your study system, and is beyond the scope of this workshop. We will see you again when you get the sequencing reads from the sequencing provider. We will then jump into the bioinformatics pipeline required to check the quality of the reads, and map the reads to the genome of your organisms of interest.",
    "crumbs": [
      "Before the experiment"
    ]
  },
  {
    "objectID": "episodes/04-differential-gene-expression.html",
    "href": "episodes/04-differential-gene-expression.html",
    "title": "Differential gene expression analysis",
    "section": "",
    "text": "(MW)\n\n\nI think this episode should already work pretty well, and covers most of the important things.\nImo, sometimes the text rather succinctly introduced difficult concepts and immediately assumes familiarity of the reader with them. I added some basic explanation to some sections which I hope will address this, e.g. regarding:\n\nWhat does design formula mean\nWhat is goal and logic of PCA (plot)\n\nSomething that’s really missing I think is talking about what “padj” means. A diagram like below, or a more explanatory variation thereof, might be useful:\n\n\n\nIllustration of p-value adjustment (multiple testing correction), source.\n\n\n\n\n\nI made a little overview of how often different DEG analysis packages are cited last year; but don’t think that’s very valuable to add here.\nThe main goal of most RNA-seq experiments is to discover which genes are differentially expressed between different groups (treatments, tissues, genotypes): the list of differentially expressed genes (DEGs). After the previous section, we now have a count table with the number of reads that map to each gene in each sample. How do we get to our goal from this table? We will need to use statistical models! In this section, we will use the DESeq2 package in R for differential gene expression analysis. Several other packages with different statistical models and assumptions exist (e.g. EdgeR and Limma): we pick DESeq2 because it is robust, widely-used, and user friendly [cite Li2022, others?].",
    "crumbs": [
      "Differential gene expression analysis"
    ]
  },
  {
    "objectID": "episodes/04-differential-gene-expression.html#feedback",
    "href": "episodes/04-differential-gene-expression.html#feedback",
    "title": "Differential gene expression analysis",
    "section": "",
    "text": "I think this episode should already work pretty well, and covers most of the important things.\nImo, sometimes the text rather succinctly introduced difficult concepts and immediately assumes familiarity of the reader with them. I added some basic explanation to some sections which I hope will address this, e.g. regarding:\n\nWhat does design formula mean\nWhat is goal and logic of PCA (plot)\n\nSomething that’s really missing I think is talking about what “padj” means. A diagram like below, or a more explanatory variation thereof, might be useful:\n\n\n\nIllustration of p-value adjustment (multiple testing correction), source.\n\n\n\n\n\nI made a little overview of how often different DEG analysis packages are cited last year; but don’t think that’s very valuable to add here.",
    "crumbs": [
      "Differential gene expression analysis"
    ]
  },
  {
    "objectID": "episodes/04-differential-gene-expression.html#reading-the-count-table-into-deseq2",
    "href": "episodes/04-differential-gene-expression.html#reading-the-count-table-into-deseq2",
    "title": "Differential gene expression analysis",
    "section": "Reading the count table into DESeq2",
    "text": "Reading the count table into DESeq2\nIn this tutorial, we will explore the transcriptomes of A. thaliana plants that experienced microgravity by growing on the International Space Station, while control plants were grown on earth. The experimental design is simple: there are three replicates in both conditions space_flight and ground_control.\nFirst we will load the packages that we need, and then load the count table and metadata file.\n\n\n\nR\n\nset.seed(1992) # some parts of analysis depend on random sampling or initialization; \n               # setting seed sets constant array of random numbers, ensuring reproducibility.\n               # this won't affect main results too much, but is thorough\n\nlibrary(DESeq2)\nlibrary(tidyverse)\nlibrary(ggrepel)\n\n\n(added comment above)\n\n\n\nR\n\n1raw_counts &lt;- read.csv(\"../data/GLDS38_raw_counts.csv\", header = T, stringsAsFactors = F)\n\n2raw_counts &lt;- raw_counts %&gt;% column_to_rownames(\"gene\")\n\nmetadata &lt;- read.csv(\"../data/samples_to_condition.csv\", header = T)\n\nraw_counts[1:4,1:4]\n\n\n\n1\n\nMake sure you use the correct path to where your data is stored. Depending on your folder structure, you may not need the ../ and you could use data/GLDS38_raw_counts.csv instead.\n\n2\n\nHere, we store the column gene as row names instead of a dedicated column.\n\n\n\n\n          Atha_WT_Col_0_sl_FLT_Rep1_G1S1 Atha_WT_Col_0_sl_FLT_Rep2_G1S2\nAT1G01010                            339                            383\nAT1G01020                            126                            117\nAT1G01030                            153                            158\nAT1G01040                           1238                            442\n          Atha_WT_Col_0_sl_FLT_Rep3_G1S3 Atha_WT_Col_0_sl_GC_Rep1_G2S1\nAT1G01010                            363                           650\nAT1G01020                             89                            60\nAT1G01030                            143                            97\nAT1G01040                            543                           783\n\n\nThat looks good! Now, it’s important to note that DESeq2 expects the sample names (columns in count table) to exactly match the sample names in the metadata file, and be in the same order! For this small dataset, we can inspect that by eye. In addition, and probably useful for larger datasets, we can use the all() function to check this.\n\n\n\nR\n\nhead(metadata)\n\n\n                     sample_name      condition\n1 Atha_WT_Col_0_sl_FLT_Rep1_G1S1   space_flight\n2 Atha_WT_Col_0_sl_FLT_Rep2_G1S2   space_flight\n3 Atha_WT_Col_0_sl_FLT_Rep3_G1S3   space_flight\n4  Atha_WT_Col_0_sl_GC_Rep1_G2S1 ground_control\n5  Atha_WT_Col_0_sl_GC_Rep2_G2S2 ground_control\n6  Atha_WT_Col_0_sl_GC_Rep3_G2S3 ground_control\n\n\n\n\n\nR\n\n1all(colnames(raw_counts) == metadata$sample)\n\n\n\n1\n\nIf this does not return TRUE, you need to reorder or rename sample names in one of your files.\n\n\n\n\n[1] TRUE\n\n\n\nCreating the dds object\nI edited the section below\nWe are now ready to create a DESeqDataSet object, commonly abbreviated as dds.  We will put our count tables and metadata in this object, and use it as input for the DESeq2 functions. DESeq2 functions will return this same object again, with added information such as normalized counts and differentially expressed genes.\n\nStoring all this related information in the one dds object helps keeps our R session clean.\nTo make one, we need to specify our experimental design ‘formula’. In this tutorial, there’s only one variable (condition): the design formula will be as simple as ~ condition. However, in multi-factor experiments it can include additional variables, can also include unwanted sources of variation such as RNA isolation batch, the researcher who extracted RNA, or on which table the plants were grown. Including these factors in the design formula will help DESeq2 to account for these soures of variation, allowing more accurate estimation of the primary condition’s effect. For example, in an experiment with a potential batch effect, treatments, and different genotypes: ~ batch + treatment + genotype. This notation is shorthand to tell DESeq2 that the final gene expression in each sample \\(y\\) should be modelled as: \\[\ny = \\beta_0 + \\beta_1 \\cdot x_\\text{batch} + \\beta_2 \\cdot x_\\text{treatment} + \\beta_3 \\cdot x_\\text{genotype} + \\epsilon\n\\] where \\(x_{...}\\) is either one or zero depending on if the condition applies or not, and \\(\\beta_i\\) are constants that need to be fitted. (Don’t worry about the \\(\\epsilon\\), this is a technical way to express that the model is not perfect and there will always be some noise in the data.) Risk of adding this is that’s it’s “scary math”, but otherwise I think the design formulae remain very mysterious. We could add example.\nIf you also want to model the interaction, that is whether the treatment effect varies by genotype, change the + to a *: ~ batch + treatment * genotype. (Separate treatment and genotype terms will automatically be included in the model when using *.)\n\n\n\nR\n\ndds &lt;- DESeqDataSetFromMatrix(countData = raw_counts, \n                              colData = metadata, \n                              design = ~ condition)\n\n\nWarning in DESeqDataSet(se, design = design, ignoreRank): some variables in\ndesign formula are characters, converting to factors",
    "crumbs": [
      "Differential gene expression analysis"
    ]
  },
  {
    "objectID": "episodes/04-differential-gene-expression.html#a-preliminary-assessment-of-your-data-using-pca",
    "href": "episodes/04-differential-gene-expression.html#a-preliminary-assessment-of-your-data-using-pca",
    "title": "Differential gene expression analysis",
    "section": "A preliminary assessment of your data using PCA",
    "text": "A preliminary assessment of your data using PCA\n(Changed title, as I think QC is put too strong.)\nI think this is a very clear text concisely explaining PCA. I understand it very well, but I’m wondering though whether for novices it might be nice to add some more “explain it to me like I’m 5 years old language” (exaggerated). Tried adding some some sentences and a graph.\nAs essential step in RNA-seq analysis is to inspect similarity between samples. In particular, we should confirm that replicates with the same treatment are similar to each other, and make sure that the experimental condition is the major source of variation in the data. In addition, these quality-control explorations will also help identify if any samples behalve as outliers, or whether there may have been a sample swap.\nIt would be very nice if there was a visualization from which we can see how samples relate to each other. For example an \\(x, y\\) plot in which the distance between indicates their similarity.\n\n\n\nA visual comparison between sample similarity.\n\n\nThis exists! We will use Principal Component Analysis (PCA) to do this. PCA is a dimensionality reduction technique that transforms complex high-dimensional data (like expression of thousands of genes) into a limited number of new variables (‘principal components’) that capture the most variation in the dataset.\n\nPerforming variance stabilization\nBefore performing the PCA itself, we need to take an import feature of RNA-seq data into account: the variance of a gene is strongly correlated to the expression level of the gene. In statistics language, our data is not homoscedastic, while PCA assumes homoscedastic data. We can solve this by performing a variance stabilizing transformation vst():\n\n\n\nR\n\nvariance_stabilized_dataset &lt;- vst(dds, blind = TRUE)\n\n\nLet’s inspect the average expression and standard deviation of each gene to show that this transformation worked. In the following plots, each dot represents one A. thaliana gene:\n\n\n\nShow the code to make the plots\n\nR\n\nlibrary(patchwork)\n\nwithout_vst &lt;- raw_counts %&gt;% \n    as.data.frame() %&gt;% \n    rownames_to_column(\"gene\") %&gt;% \n    pivot_longer(cols = - gene, names_to = \"sample\", values_to = \"count\") %&gt;% \n    group_by(gene) %&gt;% \n    summarise(gene_mean = mean(count), gene_sd = sd(count)) %&gt;% \n    ungroup() %&gt;% \n    ggplot(aes(x = log10(gene_mean), y = log10(gene_sd))) +\n    geom_point(alpha = 0.2) +\n    labs(x = \"Gene count average\\n(log10 scale)\",\n        y = \"Gene count standard deviation\\n(log10 scale)\") +\n    ggtitle(\"No variance stabilization\")\n    \nvariance_stabilised_counts &lt;- assay(variance_stabilized_dataset)\n\nwith_vst &lt;- variance_stabilised_counts %&gt;% \n  as.data.frame() %&gt;% \n  rownames_to_column(\"gene\") %&gt;% \n  pivot_longer(cols = - gene, names_to = \"sample\", values_to = \"count\") %&gt;% \n  group_by(gene) %&gt;% \n  summarise(gene_mean = mean(count), gene_sd = sd(count)) %&gt;% \n  ungroup() %&gt;% \n  ggplot(aes(x = log10(gene_mean), y = log10(gene_sd))) +\n  geom_point(alpha = 0.2) +\n  labs(x = \"Gene count average\\n(log10 scale)\",\n       y = \"Gene count standard deviation\\n(log10 scale)\") +\n  ggtitle(\"Variance stabilized\")\n\nwithout_vst | with_vst\n\n\n\n\n\n\n\n\n\n\nShow the code to make the plots\nvariance_stabilised_counts_df &lt;- variance_stabilised_counts %&gt;%\n  as.data.frame() %&gt;% \n  rownames_to_column(\"gene\")  \nwrite.csv(variance_stabilised_counts_df, \"../data_processed/variance_stabilized_dataset.csv\", row.names=FALSE)\n\n\nIndeed, we can observe that genes that are highly expressed (have high mean count) also have a high standard deviation. This correlation is no longer there after stabilizing the variance.\n\n\nPerforming the PCA\nI think we’ll need to explain what we’re doing and seeing a bit more in this section. I made some edits.\nOkay, finally we are ready to perform the PCA. DESeq2 makes this very easy for us with a simple function, plotPCA(), which directly gives us a PCA plot.\n\n\n\nR\n\nplotPCA(variance_stabilized_dataset)\n\n\n\n\n\n\n\n\n\n\nUnderstanding the PCA plot\nWhat do we see here? Dots correspond to samples, and the distance between points corresponds to gene expression similarity.\nThe x and y axis correspond to PC1 and PC2, PC standing for “principal component”. We won’t go into the details of PCA here, but will try to briefly explain what is plotted here. We could have selected two arbitrary genes and put those x and y axis, which would also produced a similar plot. But we can choose from many genes to do this, and we don’t know which ones relate to relevant changes. Instead, PCA formulates “principal components” (there are actually many more than PC1 and PC2, there’s also PC3, PC4, et cetera). When moving a step along a PC axis, this is related to specific changes in all genes. The PCs are chosen such, that most gene expression variance seen between the samples can be described by taking steps along PC1. Variance that couldn’t be captured in PC1, ie because it is of a different kind, is described by PC2, or PC3, et cetera.\n\n\nInterpretation\nSo what can we learn from the PCA plot?\n\nWe see that principal component 1 (PC1) explains 60% of the variance, while PC2 explains 29%. Those are nice scores. However, PC1 does not seem to separate our two conditions. This means that there’s another source of variation in this dataset that we are seemingly unaware of.\nWe see that PC2 nicely separates our two conditions. This is good!\n\nWe see that two samples from space_flight cluster very closely together, while one sample is quite a distant from those two. This means that this one replicate behaves a bit differently than the rest. However, since it’s still similar to the other two samples on the PC2 axis, this does not worry me.\n\n\n\nRefining the PCA analysis plot\nIf you want to have full control and make the PCA plot yourself in ggplot, you can add returnData=TRUE)\n\n\n\nR\n\npca_data &lt;- plotPCA(variance_stabilized_dataset, returnData=TRUE) \n\n\nWhile it is impossible to give examples of all situations that can occur in PCAs, we highlight a few below in fake PCA plots:\n\n\n\nShow the code to make the plots\n\nR\n\ndf_swap &lt;- data.frame(\n  PC1 = c(rnorm(5, mean = 1, sd = 0.2),   \n          rnorm(5, mean = -2, sd = 0.2)), \n  PC2 = c(rnorm(5, mean = 0.4, sd = 0.2),\n          rnorm(5, mean = 0.3, sd = 0.2)),\n  genotype = c(rep(\"WT\", 4), \"mutant\", rep(\"mutant\", 4), \"WT\"))\n\ndf_weak_sep &lt;- data.frame(\n  PC1 = c(rnorm(5, mean = 0.2, sd = 0.45),   \n          rnorm(5, mean = 0, sd = 0.6)), \n  PC2 = c(rnorm(5, mean = 0, sd = 0.25),\n          rnorm(5, mean = 0, sd = 0.25)),\n  genotype = rep(c(\"WT\", \"mutant\"), each = 5)\n)\n\np1 &lt;- df_swap %&gt;% ggplot(aes(x = PC1, y = PC2, colour = genotype)) + geom_point() +\n  xlab(\"PC1 (48%)\") +\n  ylab(\"PC2 (13%)\") +\n  ggtitle(\"Sample swap\")\n\np2 &lt;- df_weak_sep %&gt;% ggplot(aes(x = PC1, y = PC2, colour = genotype)) + geom_point() +\n    xlab(\"PC1 (12%)\") +\n    ylab(\"PC2 (4%)\") +\n    ggtitle(\"Weak separation\")\n\np1 | p2\n\n\n\n\n\n\n\n\n\n\nIn the first plot, we see one WT sample clustering with mutant samples, and vice versa. This is a clear indication that two samples were swapped somewhere in the process: during sampling, RNA extraction, cDNA synthesis, library prep, or in the metadata file. If you can trace this back in your labjournal, you could swap the sample label back. If not… it’s probably better to discard these two samples completely. In the second plot, we can see that there’s no clear separation between WT and mutant samples. In addition, the two PCs explain little of the variance present in the dataset. This is an indication that the genotype actually has little impact on the transcriptome. While worrying, this does not mean that all is lost! You can still proceed to differential expression analysis, maybe the difference between the two genotypes is quite subtle.\n\n\n\nShow the code to make the plots\n\nR\n\ndf_confounding_1 &lt;- data.frame(\n  PC1 = c(rnorm(5, mean = 1, sd = 0.45),   \n          rnorm(5, mean = -1, sd = 0.6)), \n  PC2 = c(rnorm(5, mean = 0, sd = 0.25),\n          rnorm(5, mean = 0, sd = 0.25)),\n  genotype = rep(c(\"WT\", \"mutant\"), each = 5),\n  gender = rep(c(\"male\", \"female\"), each = 5)\n)\n\np1 &lt;- df_confounding_1 %&gt;% ggplot(aes(x = PC1, y = PC2, colour = genotype)) + geom_point() +\n  xlab(\"PC1 (48%)\") +\n  ylab(\"PC2 (13%)\") +\n  ggtitle(\"Genotype effect ...\")\n\np2 &lt;- df_confounding_1 %&gt;% ggplot(aes(x = PC1, y = PC2, colour = gender)) + geom_point() +\n  xlab(\"PC1 (48%)\") +\n  ylab(\"PC2 (13%)\") +\n  ggtitle(\"... or gender effect?\")\n\np1 | p2\n\n\n\n\n\n\n\n\n\n\nIn this example, we see separation of our wildtype and mutant samples. Experiment succesful! … or is it? Upon closer inpection, we can see that gender of our samples also separates our samples in the same way. It turns out that all wildtypes were male mice, and all mutants were female. We will therefore never know if differentially expressed genes are caused by the genotype, or simply by the gender of the mice: a clear case of confounding variable. This is an experimental design flaw, and should have been caught before sampling. Yet, it happens!\n\n\n\n\n\n\nQuestion\n\n\n\nBesides PCA, how else could you assess whether replicate samples from the same treatment show similar results?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can use a correlation analysis to do this. For this analysis, we will also need the variance stabilized counts.\n\n\n\nR\n\nlibrary(pheatmap)\n\ncorrelation_matrix &lt;- cor(variance_stabilised_counts)\n\nmetadata_2 &lt;- metadata %&gt;% column_to_rownames(\"sample_name\")\n\npheatmap(correlation_matrix, annotation_row = metadata_2, \n         clustering_distance_rows = \"correlation\", \n         clustering_distance_cols = \"correlation\", \n         display_numbers = TRUE, fontsize = 7)\n\n\n\n\n\n\n\n\n\nWe can see that all the ground_control and space_flight samples cluster together. For example, ground_control samples have a 0.98 or greater correlation with each other, while they have a slightly lower correlation with space_flight samples. However, the samples still have a high correlation also accross the different treatment. This shows that the transcriptomes are actually highly similar, regardless of treatment, probably because the majority of genes is not differentially expressed.",
    "crumbs": [
      "Differential gene expression analysis"
    ]
  },
  {
    "objectID": "episodes/04-differential-gene-expression.html#differentially-expressed-genes-analysis",
    "href": "episodes/04-differential-gene-expression.html#differentially-expressed-genes-analysis",
    "title": "Differential gene expression analysis",
    "section": "Differentially expressed genes analysis",
    "text": "Differentially expressed genes analysis\nMinor: If we talk about DEG analysis, we shouldn’t we say “differentially expresed genes analysis” when spelling it out?– I edited this now.\nFinally, now that we’ve finished our preliminary analysis of the data, we can proceed with differentially expressed genes (DEG) analysis!\nDESeq2 handles all steps of DEG analysis, from sample normalization to the statistical models and tests in one function. Easy! We run this function with the dds object as input, while storing the output in the dds object as well. In this way, we will ‘fill’ the dds object with the new analysis. R will now print all the individual steps that the DESeq() function performed for us.\n\n\n\nR\n\ndds &lt;- DESeq(dds)\n\n\nestimating size factors\n\n\nestimating dispersions\n\n\ngene-wise dispersion estimates\n\n\nmean-dispersion relationship\n\n\nfinal dispersion estimates\n\n\nfitting model and testing\n\n\nTODO:\n\nshow plot of normalization effect\nWrite scaled counts to file\n\n\nLists of DEGs\nNow, to extract the list of DEGs from the dds we run another line of code. The argument alpha is used to specify the p-value cutoff for significance, the default value is alpha = 0.1. We will use 0.05 here. We will also sort the table on p-value:\n\n\n\nR\n\n1res &lt;- results(dds, alpha = 0.05)\n\n2DEGs &lt;- res %&gt;%\n  as.data.frame() %&gt;% \n  rownames_to_column(\"genes\") %&gt;%\n  mutate(minus_log10_pvalue = -log10(padj)) %&gt;% \n  arrange(padj) \n\nhead(DEGs) \n\n3write.csv(DEGs, '../data_processed/all_genes_spaceflight_vs_ground.csv', quote = FALSE, row.names = FALSE)\n\n\n\n1\n\nGenerate results table\n\n2\n\nTurn results table into a data frame, generate a genes column from the rownames, make a new column with -log10 transformed p-values, then sort by adjusted p-value.\n\n3\n\nWrite to a file!\n\n\n\n\n      genes  baseMean log2FoldChange     lfcSE      stat       pvalue\n1 AT5G04120  456.5672       3.626601 0.2462679  14.72625 4.373302e-49\n2 AT2G28780 1964.3983      -3.630964 0.3295515 -11.01790 3.132877e-28\n3 AT1G62280  217.8345      -3.901515 0.3558773 -10.96309 5.750122e-28\n4 AT1G32450 5241.0272      -3.468312 0.3201047 -10.83493 2.351468e-27\n5 AT1G30530  708.2953       2.033682 0.1938998  10.48832 9.775358e-26\n6 AT1G15380  739.4577      -2.714855 0.2601613 -10.43528 1.711141e-25\n          padj minus_log10_pvalue\n1 9.870980e-45           44.00564\n2 3.535609e-24           23.45154\n3 4.326200e-24           23.36389\n4 1.326874e-23           22.87717\n5 4.412792e-22           21.35529\n6 6.437029e-22           21.19131\n\n\nTODO:\n\nExplain the DEGs dataframe, what is base mean, what is log2 fold change?\nLook at DESeq2 shrinkage of fold changes\nAdd piece on extra contrasts\nTalk about the difference between pvalue and padj!\n\n\n\nVolcano plots\nOne way to visualize DEG results is to display them in a Volcano plot. Such a plot shows a measure of effect size (log2 fold changes) versus a measure of significance. There are tools available (developed by Joachim Goedhart, assistant professor at SILS) to help you make such a plot using the DEG list we just saved as a .csv file. Alternatively, we can make one ourselves for full control of the plot:\n\n\n\nR\n\n# Define fold change and p-value cutoffs\nlfc_cutoff &lt;- 1.5\npadj_cutoff &lt;- 0.05\n\n# Make new categorical variable containing significance information\nDEGs &lt;- DEGs %&gt;% \n        mutate(significance = case_when(\n          padj &lt; padj_cutoff & log2FoldChange &gt; lfc_cutoff ~ 'Significantly upregulated',\n          padj &lt; padj_cutoff & log2FoldChange &lt; -lfc_cutoff ~ 'Significantly downregulated',\n          padj &lt; padj_cutoff ~ 'Significant but small effect size',\n          TRUE ~ 'Not significant'\n        ))\n\nDEGs_subset &lt;- DEGs %&gt;% filter(significance == \"Significantly upregulated\" | significance == \"Significantly downregulated\")\nwrite.csv(DEGs_subset, '../data_processed/DEGs_spaceflight_vs_ground.csv', quote = FALSE, row.names = FALSE)\n\ncolors &lt;- c(\"Significantly upregulated\"=\"#E69F00\", \"Significantly downregulated\"=\"#56B4E9\", \"Not significant\"=\"gray80\", \"Significant but small effect size\" = 'grey50')\n\n# select top 10 genes to highlight\ntop_genes &lt;- DEGs[1:10, ]\n\nvolcano &lt;- DEGs %&gt;% \n  ggplot(aes(x = log2FoldChange, y = -log10(padj), colour = significance)) +\n  geom_point(alpha = 0.5, size = 0.8) + \n  geom_hline(aes(yintercept = -log10(padj_cutoff)), linetype = \"dashed\") +\n  geom_vline(aes(xintercept = lfc_cutoff), linetype = \"dashed\") +\n  geom_vline(aes(xintercept = -lfc_cutoff), linetype = \"dashed\") +\n  geom_point(data = top_genes, shape = 21,fill = NA, color = \"black\") +  # Highlight top10\n  geom_text_repel(data = top_genes, aes(label = genes), size = 2, min.segment.length = 0) +\n  scale_color_manual(values=colors) +\n  xlim(c(-10,10)) +\n  theme_bw() \n\nggsave(\"volcano_plot.png\", volcano, width = 14, height = 8, units = \"cm\")\n\n\nWarning: Removed 10262 rows containing missing values (`geom_point()`).\n\nvolcano \n\nWarning: Removed 10262 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nWe can plot the DESeq2-normalized counts of two genes, just to confirm whether the volcano plot is correct. We pick one that is highly upregulated in space_flightconditions (AT5G04120), and one that is strongly downregulated (AT1G62280).\n\n\n\nR\n\ngene_1 &lt;- plotCounts(dds, gene=\"AT5G04120\", intgroup=\"condition\", \n                returnData=TRUE)\n\ngene_2 &lt;- plotCounts(dds, gene=\"AT1G62280\", intgroup=\"condition\", \n                        returnData=TRUE)\n\ngene_1 %&gt;% ggplot(aes(x = condition, y = count, colour = condition)) +\n  geom_jitter(width = 0.05) +\n  theme_bw()\n\n\n\n\n\n\n\n\ngene_2 %&gt;% ggplot(aes(x = condition, y = count, colour = condition)) +\n  geom_jitter(width = 0.05) +\n  theme_bw()\n\n\n\n\n\n\n\n\nYep, that seems about right.\n\n\nWhat’s next\nAdded link to overall process.\nHopefully, your experiment yielded many genes that showed differential expression that was significant. This also poses you with a problem: which of those are biologically most relevant to look into further? How do we e.g. sort out 200+ differentially expressed genes, what do those expression changes mean, to which biological processes do these relate?\nPerhaps you had a very clearly defined hypothesis, and can link some of the top differentially expressed genes to your research question. Great!\nOtherwise (and more common probably) you’ll need to now start a carefull dissection of your results to design validation and follow-up experiments. This can be done by many means, which we’ll partially dive into in the next section.\nNext, we will display the our gene expression data in a heatmap, another popular plot of choice for RNA-seq experiments. In addition, we will look into charactering the molecular functions of up- and down-regulated genes using GO term annotation and enrichment.",
    "crumbs": [
      "Differential gene expression analysis"
    ]
  },
  {
    "objectID": "episodes/03-mapping-reads.html",
    "href": "episodes/03-mapping-reads.html",
    "title": "From reads to alignments",
    "section": "",
    "text": "The structure of going through main important commands during mapping is good, imo.\nI think there are some challenges with teaching this material in a short time.\nI think the challenge here is to both provide insights into the mapping (etc) process as well as supply the participants with practical means to perform mapping themselves.\n\n\n\n\n\nPractical means can also be the Galaxy server, or another existing pipeline, and this episode just functions as a way to make people understand what’s going on.\nI think what makes it challenging is that currently the process is explained by a single example, and people won’t know how to modify the process for different organisms, types of data etc. The code shown however already almost constitutes a pipeline template. Perhaps we can:\n\nAlso add some “extended info” where we provide a more extensive command template that includes options for different situatinos (e.g. single read, different read length, different organism, etc).\nInclude a full template script at the end, that includes documentation (in comments) about how one should run and adjust the commands for their needs.\n\n(might already exist somewhere)\n\n\nHowever, it will also remain a challenge that people need to set up a chrunchomics account and get things working there. Perhaps we can write a brief tutorial how to set this up as well? (This can than be material not included in the course, but available to those interested.)\n\n\n\nI think it would also be beneficial to “paint the big picture” upfront (experiment –&gt; count table, see below) and also briefly place each of the steps of this episode in the “big picture” pipeline at the beginning of each paragraph.\n\n\n\nChallenge: people need to understand terminal, piping, shell scripts, etc. Seems a bit much. Maybe take a moment for basics of those too? (And do these things with live coding?) Which editor to use?\n\nQuick tour of terminal basics would include imho:\n\nNavigation (cd, ls, cat, mkdir, pwd, mv, cp, piping?, echo? setting parameters?)\nCalling a program (e.g. “python”, or “echo hello”)\nWriting a script that can be called by a program (for loop that calls hello world python script?)\nSee also: https://swcarpentry.github.io/shell-novice/\n\n\n\n\n\nI think here it would also be beneficial to do a type along in Caprentries style?\nThe code is not extremely long, and will be instructive.\nThere would need to be some more explaining in between.\nOther option: make it purely a notebook that people go through in their own pace and explain stuff personally or colloqually if appropriate (this is how the ML workshop I followed did it).\n\n\n\n\nMovie about sequencing protocol:\n\nYT illumina\nThe moment is there: you received the FASTQ files from your sequencing provider! Now what?",
    "crumbs": [
      "From reads to alignments"
    ]
  },
  {
    "objectID": "episodes/03-mapping-reads.html#feedback",
    "href": "episodes/03-mapping-reads.html#feedback",
    "title": "From reads to alignments",
    "section": "",
    "text": "The structure of going through main important commands during mapping is good, imo.\nI think there are some challenges with teaching this material in a short time.\nI think the challenge here is to both provide insights into the mapping (etc) process as well as supply the participants with practical means to perform mapping themselves.",
    "crumbs": [
      "From reads to alignments"
    ]
  },
  {
    "objectID": "episodes/03-mapping-reads.html#some-further-thoughts",
    "href": "episodes/03-mapping-reads.html#some-further-thoughts",
    "title": "From reads to alignments",
    "section": "",
    "text": "Practical means can also be the Galaxy server, or another existing pipeline, and this episode just functions as a way to make people understand what’s going on.\nI think what makes it challenging is that currently the process is explained by a single example, and people won’t know how to modify the process for different organisms, types of data etc. The code shown however already almost constitutes a pipeline template. Perhaps we can:\n\nAlso add some “extended info” where we provide a more extensive command template that includes options for different situatinos (e.g. single read, different read length, different organism, etc).\nInclude a full template script at the end, that includes documentation (in comments) about how one should run and adjust the commands for their needs.\n\n(might already exist somewhere)\n\n\nHowever, it will also remain a challenge that people need to set up a chrunchomics account and get things working there. Perhaps we can write a brief tutorial how to set this up as well? (This can than be material not included in the course, but available to those interested.)\n\n\n\nI think it would also be beneficial to “paint the big picture” upfront (experiment –&gt; count table, see below) and also briefly place each of the steps of this episode in the “big picture” pipeline at the beginning of each paragraph.\n\n\n\nChallenge: people need to understand terminal, piping, shell scripts, etc. Seems a bit much. Maybe take a moment for basics of those too? (And do these things with live coding?) Which editor to use?\n\nQuick tour of terminal basics would include imho:\n\nNavigation (cd, ls, cat, mkdir, pwd, mv, cp, piping?, echo? setting parameters?)\nCalling a program (e.g. “python”, or “echo hello”)\nWriting a script that can be called by a program (for loop that calls hello world python script?)\nSee also: https://swcarpentry.github.io/shell-novice/\n\n\n\n\n\nI think here it would also be beneficial to do a type along in Caprentries style?\nThe code is not extremely long, and will be instructive.\nThere would need to be some more explaining in between.\nOther option: make it purely a notebook that people go through in their own pace and explain stuff personally or colloqually if appropriate (this is how the ML workshop I followed did it).\n\n\n\n\nMovie about sequencing protocol:\n\nYT illumina",
    "crumbs": [
      "From reads to alignments"
    ]
  },
  {
    "objectID": "episodes/03-mapping-reads.html#quality-control-fastqc",
    "href": "episodes/03-mapping-reads.html#quality-control-fastqc",
    "title": "From reads to alignments",
    "section": "Quality control: fastqc",
    "text": "Quality control: fastqc\n\nI think some context is lacking here. What is our goal? Maybe add paragraph at start that outlines the whole process?\nOur goal is to obtain count table, but what we have is just sequence information.\nSo we should convert sequence information to genes, and count observations of each genes.\nBeforehand, we want to make sure sequence information is solid –&gt; QC.\n\nThe first step in the RNA-seq workflow is to assess the quality of the sequencing reads. Sequence reads generated from next-generation sequencing technologies come in the FASTQ file format. This file format evolved from FASTA: it contains sequence data, but also contains quality information. For a single record (sequence read) there are four lines, each of which are described below:\n\n\n\n\n\n\n\nLine\nDescription\n\n\n\n\n1\nAlways begins with ‘@’ and then information about the read\n\n\n2\nThe actual DNA sequence\n\n\n3\nAlways begins with a ‘+’ and sometimes the same info in line 1\n\n\n4\nHas a string of characters which represent the quality scores; must have same number of characters as line 2\n\n\n\nLet’s run fastqc on one sample:\n\n\nfastqc is now suddenly used without introduction.\nalso terminal commands are used without introduction\n\nHowever, I like the focus on practical stuff, without extensive explantations.\nPerhaps work with information boxes to explain what each tool is?\n\n\n\n\n\n\n\nBio-inf tool: FastQC\n\n\n\nFastQC is a quality control tool for DNA or RNA sequencing data. It takes the raw sequence files (FASTQ format) and quickly checks for common issues, like overall read quality, presence of adapters, unusual base composition, or overrepresented sequences. The output is a simple report with plots and summaries that help you see if your sequencing run worked well or if there might be problems before doing further analysis.\n(added by mw/text by chatGPT)\n\n\n\n\n\nbash\n\nfastqc -o fastqc /datasets/Arabidopsis_sample1.fq.gz\n\n\nDoing this manually for every sample would be quite tiring, especially when we would have many samples. Let’s write a bash for loop to take care of this for us:\n\n\n\nbash\n\nfor filename in  /datasets/*.fq.gz\n  do\n    fastqc -o fastqc $filename\n  done\n\n\nI think for a command like this, a template file (see comments above) with more extensive documentatino makes sense. Comments could be added explaining very precisely what every part of the command is doing (including every small detail, e.g. do and done being keywords that begin/end the loop etc.).\n\nHere we define a variable filename that will subsequently get the values of all datasets matching the /datasets/*.fq.gz statement, where * acts as a wildcard.\nHere we add the actual command, where $filename will subsequently be filled in with all of our four filenames.\n\nfastq generates reports of each sample in .html format:\n\n\n\nbash\n\nls ... # TODO: add ls outcome here to show that we have 4 .html files now\n\n\nLet’s download one of them, and inspect the results:\n\n\n\nbash\n\n# TODO: download to local instructions here (if you are working on a server)\n\n\nfastqc gives the reads of each sample a score (Pass, Warning, or Fail) on several different modules and this is reported in the Summary. The next section contains basic statistics like the number of reads, average sequence length, and the GC content. Generally it is a good idea to keep track of the total number of reads sequenced for each sample and to make sure the read length and %GC content is as expected. One of the most important analysis modules is the “Per base sequence quality” plot. This plot provides the distribution of quality scores at each position in the read across all reads. This plot can alert us to whether there were any problems occuring during sequencing and whether we might need to contact the sequencing facility. Other modules are discussed in detail here. Note that nearly all sequencing datasets will show yellow warnings or red fails: fastqc is quite conservative. Your experiment is not lost if you get warnings or fails, but it warrants additional inspection of the reads.\nPerhaps also suggest that if they suspect something wrong they could contact us/their sequencer/their favorite bioinformatician.\nTODO: add screenshots of good/bad fastqc results\n\nI think it would be nice to not only include screenshot good/bad fastqc results, but also clearly (e.g. add some arrows with text) annotate those pictures explaining/highlighting how to interpret important numbers / features.\nSort of a “cheat sheet” for fastq.",
    "crumbs": [
      "From reads to alignments"
    ]
  },
  {
    "objectID": "episodes/03-mapping-reads.html#trimming-trimmomatic",
    "href": "episodes/03-mapping-reads.html#trimming-trimmomatic",
    "title": "From reads to alignments",
    "section": "Trimming: trimmomatic",
    "text": "Trimming: trimmomatic\nA common anomaly detected by fastqc is sequencing adapters still being present some of the the reads (shown in Overrepresented sequences table). This is known as ‘adapter contamination’, and the presence of these adapter sequences in the reads might affect how the reads map to the genome of interest. So, we need to get rid of them. We will trimmomatic to do this. In addition, we can ask trimmomatic to trim low quality bases from the reads.\n\n\n\nbash\n\n# TODO: add trimmomatic command here\n\n\n\n\n\n\n\n\nExercise\n\n\n\nAfter running trimmomatic, the adapter contamination should be gone.\n\nHow could you check whether trimmomatic indeed did it’s job?\nWrite a command to check this.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nWe can run fastqc again, this time on the trimmed reads.\n\n\n\n\n\nbash\n\nfastqc -o /workspace/fastqc /datasets/Arabidopsis_sample1.trimmed.fq.gz\n\n\nBy inspecting the .html report of the trimmed reads, we should see that the quality of the read sets has now improved.",
    "crumbs": [
      "From reads to alignments"
    ]
  },
  {
    "objectID": "episodes/03-mapping-reads.html#mapping-star",
    "href": "episodes/03-mapping-reads.html#mapping-star",
    "title": "From reads to alignments",
    "section": "Mapping: STAR",
    "text": "Mapping: STAR\nOur reads are now ready for mapping. Mapping reads means figuring out where each read from the RNA-seq experiment originally came from within the genome. For RNA-seq experiments, it’s important to pick a splice-aware aligner, since a RNA-seq read can span an exon-intron-exon boundary\nTODO: add a figure here to demonstrate this, like the one found here.\n\n\n\n\n\n\nQuestion\n\n\n\nSo, for RNA-seq we need splice-aware aligners. Can you come up with an experiment that would not require a splice-aware aligner program?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIn experiments where we don’t need to think about exon-intron boundaries. This is the case when the reads originate from genomic DNA, for example for whole genome sequencing experiments, or enrichment sequencing experiments like Chip-Seq.\n\n\n\nTo use an aligner, we must first get the reference genome and then index the reference genome. Indexing the genome prepares the genome in a way that allows a computer to search it efficiently. The genome, a multi-million basepair long string of text, is encoded into a different, computer-friendly datastructure such as a suffix tree. The details of this procedure are beyond the scope of this workshop, but it’s important to do it. So, let’s go ahead and download the Arabidopsis thaliana reference genome, and index it:\n\nI think important information is where you can get reference genomes and additional information (eg gtf files). Will be usefull to add info-box about this as well. E.g. include:\n\ntypically can be downloaded from NCBI/Ensembl\nbeware there are multiple versions, track which one used\nyou need to click here and here to find and download genome\n\n\n\n\n\nbash\n\n# TODO: Add download command here (via wget), OR already have the genome in the github repo\n# TODO: Add STAR index command here\n\n\nAllright, let’s finally run STAR:\n\n\n\nbash\n\n# TODO: Add STAR command here\n\n\nWe can inspect a mapping summary in a file generated by STAR called final.out:\n\n\n\nbash\n\n# TODO: Add cat final.out output\n\n\nIt’s important to check how many reads did not map to the reference genome. A high proportion of unmapped reads can be a warning sign that something went wrong in your experiment or analysis. The explanations may be technical (bad read quality), bioinformatical (perhaps you used the wrong reference genome!), or biological — it has been well documented that around 11% of primate and rodent cell-line RNA-seq datasets available on NCBI in 2015 were contaminated with mycoplasma RNA (Olarerin-George & Hogenesch, 2015). Likewise, 8,5% of all Arabidopsis thaliana NCBI RNA-seq datasets are contaminated with a virus that does not cause any disease symptoms, but can cover up to 80% of all reads generated in an RNA-seq experiment (Verhoeven et al., 2022). That said, we don’t need to aim for 100% reads mapped to the reference genome. There will always be some contamination, or your studied individual possesses genetic information not present in the reference genome.\nTODO: (Maybe as an additional exercise?) Add one subsetted dataset to demonstrate this, from the verhoeven paper.\nCan we add some quantitative guidelines when people need to worry? (To get these numbers, we could also inquire at ppl who regularly perform mapping, like MAD group ppl (Wim/Martijs?).)\n\nBAM and SAM files\n\nNot sure, consideration: is “the mapped reads” use of jargon, that might require some explaining? Same would then apply to other jargon.\nE.g. sugg: “The output of STAR are files in which the mapping of our original sequences to DNA locations are stored. These are .bam and .sam files (..)”\n\nThe mapped reads are stored in a .bam file by STAR. .bam and .sam files keep information for each individual read and its alignment to the genome. .sam files do this in a tab-seperated, human readable format, while .bam files store the same information in a binary file format that’s not readable for humans, but is much more efficient to process and store by computers. samtools is a widely used program to inspect and manipulate .sam and .bam files. Like many command line programs, samtools commands can be connected to each other via the pipe symbol |, and the results can be stored in a new file using the &gt; symbol.\n\n\n\nbash\n\nhead xyz.sam # TODO: add correct filename here\n\n\n\n\n\n\n\n\nExercise\n\n\n\nUse the head command to inspect a .bam file.\n\nWhat do you see?\nUse samtools view command, piped (using |) into a common Unix program, to inspect the first 10 lines of the file.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\nbash\n\nhead xyz.bam # TODO: add correct filename here\n\n\nThe output looks like gibberish, because .bam files are a binary file format. You can use samtools view to make samtools read the binary file, and then pipe that result into the head function to show the first 10 lines:\n\n\n\nbash\n\nsamtools view xyz.bam | head # TODO: add correct filename here\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nUse the two following commands on a .bam file, and interpret the output.\n\nsamtools flagstat\nsamtools idxstats (Note: before running this command, you need to index the .bam file using samtools index xyz.bam)\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nsamtools flagstat shows us (just like the STAR log file) how many reads were mapped correctly. In addition, it tells us whether read pairs (if mapping paired-end data) mapped together as expected.\nsamtools idxstats shows us how many reads were mapped to each chromosome of the reference genome. This is useful to confirm whether the entire genome is evenly covered, or that there may be overrepresentation on e.g. the mitochondrial DNA.\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nSo far, we only trimmed and mapped one sample. Write a bash for loop to process all four samples.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\nbash\n\nfor filename in  /datasets/*.fq.gz \n  do\n    # TODO: add trimmomatic command\n    # TODO: add STAR command\n  done\n\n\n\n\n\n\n\nInspecting the mapping on a genome browser\nI like this a load, but in view of time I think this part should be made optional. Maybe existence of viewer can be mentioned during “lecture” part of workshop, but only talk about screenshot for ±1 minute.\nTODO:\n\ndownload one bam + bai file and inspect mapping in genome browser\nobserve: only (or at least majority) reads map in genes (if this is not the case, something is wrong! either gDNA contamination, or bad annotation)\nobserve split reads across introns\nwe can’t inspect all samples manually like this, so we will need to count reads, which we will do in the next section.",
    "crumbs": [
      "From reads to alignments"
    ]
  },
  {
    "objectID": "episodes/03-mapping-reads.html#counting-featurecounts",
    "href": "episodes/03-mapping-reads.html#counting-featurecounts",
    "title": "From reads to alignments",
    "section": "Counting: featureCounts",
    "text": "Counting: featureCounts\n\n\n\nbash\n\n# TODO: add featureCounts command here",
    "crumbs": [
      "From reads to alignments"
    ]
  },
  {
    "objectID": "episodes/03-mapping-reads.html#a-note-on-the-specific-tools-used-here",
    "href": "episodes/03-mapping-reads.html#a-note-on-the-specific-tools-used-here",
    "title": "From reads to alignments",
    "section": "A note on the specific tools used here",
    "text": "A note on the specific tools used here\nIn bioinformatics, there are often many ways to reach the same goal. Here we have selected mapping, trimming and counting tools that we have available and have experience with, but there are many others that perform just as well. The following table highlights a few popular alternative options:\n\n\n\nTask\nTool used here\nAlternative tools\n\n\n\n\nTrimming\nTrimmomatic\ncutadapt, fastp\n\n\nMapping\nSTAR\nHISAT2\n\n\nCounting\nfeatureCounts\nStringTie\n\n\n\nPotentially add: trimgalore, bwa-mem(2) (not splice aware)",
    "crumbs": [
      "From reads to alignments"
    ]
  },
  {
    "objectID": "episodes/03-mapping-reads.html#streamlining-read-mapping-procedure",
    "href": "episodes/03-mapping-reads.html#streamlining-read-mapping-procedure",
    "title": "From reads to alignments",
    "section": "Streamlining read mapping procedure",
    "text": "Streamlining read mapping procedure\nIf you find this process quite cumbersome, then I have good news for you! There are pipelines available that streamline the chain of commands required for mapping:\n\nsnakemake_rnaseq, developed at the Bleeker Lab (UvA).\nnf-core/rnaseq, developed and maintained by the Nextflow community.\n\nTo add: Galaxy server\nA full instruction of these pipelines is beyond the scope of this workshop. Also, we wish to highlight that it is very insightful to have run all the steps by yourself rather than in a pipeline.",
    "crumbs": [
      "From reads to alignments"
    ]
  },
  {
    "objectID": "episodes/05-pathway-enrichment.html",
    "href": "episodes/05-pathway-enrichment.html",
    "title": "Enrichment analysis",
    "section": "",
    "text": "I wonder how much time there’s left if everything before this is covered, so I’d keep this section rather short to essentials. If people are able to generate a DEG table they’ve already come a long way.\n(No further feedback since this section isn’t finished yet I think.)",
    "crumbs": [
      "Enrichment analysis"
    ]
  },
  {
    "objectID": "episodes/05-pathway-enrichment.html#clustering-and-heatmaps",
    "href": "episodes/05-pathway-enrichment.html#clustering-and-heatmaps",
    "title": "Enrichment analysis",
    "section": "Clustering and heatmaps",
    "text": "Clustering and heatmaps\nTODO: add some text to describe the heatmap\nRead the processed data into memory:\n\n\n\nR\n\nlibrary(tidyverse)\n\n\nWarning: package 'tidyverse' was built under R version 4.1.2\n\n\nWarning: package 'tibble' was built under R version 4.1.2\n\n\nWarning: package 'tidyr' was built under R version 4.1.2\n\n\nWarning: package 'readr' was built under R version 4.1.2\n\n\nWarning: package 'purrr' was built under R version 4.1.2\n\n\nWarning: package 'dplyr' was built under R version 4.1.2\n\n\nWarning: package 'forcats' was built under R version 4.1.2\n\n\nWarning: package 'lubridate' was built under R version 4.1.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidyheatmaps)\n\nvariance_stabilised_counts &lt;- read.csv('../data_processed/variance_stabilized_dataset.csv')\nmetadata &lt;- read.csv(\"../data/samples_to_condition.csv\", header = T)\nDEGs &lt;- read.csv('../data_processed/DEGs_spaceflight_vs_ground.csv', header = T)\n\nselection &lt;- DEGs$genes\n\nvsc_selection &lt;- variance_stabilised_counts %&gt;% \n                    filter(gene %in% selection) %&gt;%\n                    pivot_longer(cols = - gene, names_to = \"sample\", values_to = \"vst_counts\") %&gt;% \n                    merge(metadata, by.x = \"sample\", by.y = \"sample_name\") \n\n\n\n\nR\n\nheatmap &lt;- tidyheatmap(df = vsc_selection,\n            rows = gene,\n            columns = sample,\n            values = vst_counts,\n            scale = \"row\",\n            annotation_col = c(condition),\n            gaps_col = condition,\n            cluster_rows = TRUE,\n            # cluster_cols = TRUE,\n            color_legend_n = 7,\n            show_rownames = TRUE,\n            show_colnames = FALSE\n            # filename = \"heatmap.pdf\"\n)\n\nheatmap",
    "crumbs": [
      "Enrichment analysis"
    ]
  },
  {
    "objectID": "episodes/05-pathway-enrichment.html#enrichment-analysis-of-gene-lists",
    "href": "episodes/05-pathway-enrichment.html#enrichment-analysis-of-gene-lists",
    "title": "Enrichment analysis",
    "section": "Enrichment analysis of gene lists",
    "text": "Enrichment analysis of gene lists\nWe want to assign some sort of funtion or pathway to a cluster / list of genes. To do this we can use GO term enrichment.\nTODO:\n\nAdd description to do this in a webserver e.g. g:profiler. Seems up to date and also looks like it contains many different organisms.\nAdd instructions to do this in code via clusterProfiler\nThe example dataset is from Arabidopsis but preferably the instructions and code should work for a wide range of organisms, such that the instructions are easily usable for anyone.",
    "crumbs": [
      "Enrichment analysis"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "(MW)\n\n\nThis is coming along very nicely!! And I think it might be managable to compress everything in 2-3 afternoons.\nI have added feedback to each of the episodes in these orange boxes.\n– Martijn\n\n\n(TO DO: Add this from notes.)\nWelcome to the RNA-seq workshop of the bioDSC. This workshop will introduce you to the basics of gene expression analysis using RNA-Seq. It is going to be fun and empowering! You will discover how the total RNA pool of an organism is converted to short sequences called “reads” that can in turn be used to get insights into gene expression. Through careful experimental design, this gene expression information can answer research questions and offer biological insights.\nThe workshop consists of two core parts:\nThe materials on this website are meant to be discussed in two four-hour trainer-led workshop sessions. However, it should also be possible to follow the materials on your own, at your own pace. Regardless of how you go through the materials, we hope that you will learn something useful!"
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "Welcome",
    "section": "Learning objectives",
    "text": "Learning objectives\nAfter this workshop, you should be able to:\n\nIdentify good practices when designing a RNA-Seq experiment\nAssess the quality of RNA-seq sequencing data (“reads”) using the command-line instructions\nAlign RNA-seq reads to a reference genome using a splice-aware aligner (e.g. STAR).\nGenerate a count matrix from the RNA-seq data alignment\nPerform a QC of your experiment through Principal Component Analysis (PCA) and sample clustering.\nExecute a differential gene expression analysis using R and the DESeq2 package.\nBe able to create key plots: volcano plot, heatmap and clustering of differentially expressed genes."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Welcome",
    "section": "Schedule",
    "text": "Schedule\ninsert table here\n\nTrying to estimate times for each parts.\n\n\n\n\n\n\n\n\n\nDay\nEpisode\nDuration\nTime\n\n\n\n\nDay 1\nExperimental considerations\n30 min\n13:00\n\n\nDay 1\nFrom FASTQ to count table – code along\n60 min\n13:30\n\n\nDay 1\nBreak\n30 min\n14:30\n\n\nDay 1\nFrom FASTQ to count table – code yourself\n90 min\n15:00\n\n\nDay 1\n(end)\n/\n16:30\n\n\n\n\n\n\n\n\n\n\n\n\nDay\nEpisode\nDuration\nTime\n\n\n\n\nDay 1\nDifferential expression analysis – code along\n60 min\n13:00\n\n\nDay 1\nDifferential expression analysis – code yourself\n90 min\n13:00\n\n\nDay 1\nBreak\n30 min\n14:30\n\n\nDay 1\nEnrichment analysis – lecture\n30 min\n15:00\n\n\nDay 1\nEnrichment analysis – code yourself\n30 min\n15:00\n\n\nDay 1\n(end)\n/\n17:00\n\n\n\nPerhaps make this also three afternoons?? The second day seems awefully tight.."
  },
  {
    "objectID": "index.html#maintainers",
    "href": "index.html#maintainers",
    "title": "Welcome",
    "section": "Maintainers",
    "text": "Maintainers\nCurrent maintainers of this workshop page are members of the bioDSC (University of Amsterdam)."
  },
  {
    "objectID": "index.html#credits",
    "href": "index.html#credits",
    "title": "Welcome",
    "section": "Credits",
    "text": "Credits\nThis workshop is based on other teaching materials available online. The primary source is the RNA-seq lesson designed by the Science Park Study Group, which in turn was based on Harvard Chan Bioinformatics Core RNA-seq materials."
  },
  {
    "objectID": "index.html#some-general-feedback",
    "href": "index.html#some-general-feedback",
    "title": "Welcome",
    "section": "",
    "text": "This is coming along very nicely!! And I think it might be managable to compress everything in 2-3 afternoons.\nI have added feedback to each of the episodes in these orange boxes.\n\n\n(TO DO: Add this from notes.)"
  },
  {
    "objectID": "index.html#feedback",
    "href": "index.html#feedback",
    "title": "Welcome",
    "section": "",
    "text": "This is coming along very nicely!! And I think it might be managable to compress everything in 2-3 afternoons.\nI have added feedback to each of the episodes in these orange boxes.\n– Martijn\n\n\n(TO DO: Add this from notes.)"
  }
]